{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import collections\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "sb.set_palette(sb.color_palette('Paired'))\n",
    "\n",
    "NAR = '20'\n",
    "print(\"NAR:\",NAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLiteContext:\n",
    "    def __init__(self):\n",
    "        self.conn = sqlite3.connect('/home/ghsong/django-substring/mysite/db.sqlite3')\n",
    "        self.conn.row_factory = dict_factory\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self.conn.cursor()\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.conn.commit()\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "    with SQLiteContext() as cur:\n",
    "        cur.execute(query)\n",
    "        return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tmpl = 'SELECT exp_date, algorithm_id, dataset_id, parameter, result FROM projectManager_expitem WHERE project_id=1 AND invalid=0 {} ORDER BY -exp_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_factory(cursor, row):\n",
    "    d = {}\n",
    "    for idx, col in enumerate(cursor.description):\n",
    "        d[col[0]] = row[idx]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2dict(s):\n",
    "    return ast.literal_eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_list = ['PrefixSearch_6.32', 'PkwiseSynSearch_2.00', 'FaerieSynSearch_1.02']\n",
    "alg_name_final = 'PrefixSearch_6.32'\n",
    "# alg_list = ['PrefixSearch_6.20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting_list = ['RSS-NAIVE', 'RSS-LPR', 'RSS-C', 'RSS-CP', 'RSS-CPL', 'RSS-CPLPR', 'RSS-PKWISE']#, 'RSS-PKWISE2', 'RSS-PKWISE3']\n",
    "# setting_list = ['RSS-NAIVE', 'RSS-C', 'RSS-P', 'RSS-L', 'RSS-PR', 'RSS-CP', 'RSS-CL', 'RSS-PL','RSS-CPL', 'RSS-CPLPR']\n",
    "# setting_list = ['RSS-NAIVE', 'RSS-C', 'RSS-P', 'RSS-L',  'RSS-CP', 'RSS-CL', 'RSS-PL','RSS-CPL', 'RSS-CPPR', 'RSS-CPLPR']\n",
    "# setting_list = ['RSS-NAIVE', 'RSS-C', 'RSS-P', 'RSS-CP', 'RSS-CL', 'RSS-PL', 'RSS-CPL']\n",
    "setting_list = ['RSS-NAIVE', 'RSS-CL', 'RSS-PL', 'RSS-CP', 'RSS-CPL', 'PKDUCK-W', 'PKWISE-R', 'FAERIE-R']\n",
    "\n",
    "def get_setting_label(aid, dict_param):\n",
    "#     print(aid, dict_param)\n",
    "    alg_name = dict_aid[aid]\n",
    "#     assert alg_name in alg_list\n",
    "    if alg_name.startswith('PrefixSearch') or alg_name.startswith('ZeroPrefixSearch'):\n",
    "        return get_setting_label_PrefixSearch(dict_param)\n",
    "    elif alg_name.startswith('PkwiseSynSearch'):\n",
    "        return get_setting_label_PkwiseSynSearch(dict_param)\n",
    "    elif alg_name.startswith('FaerieSynSearch_'):\n",
    "        return 'FAERIE-R'\n",
    "    elif alg_name.startswith('NaiveContainmentSearch_'):\n",
    "        return 'RSS-JC-NAIVE'\n",
    "    elif alg_name.startswith('ContainmentPrefixSearch_'):\n",
    "        return 'RSS-JC'\n",
    "\n",
    "    \n",
    "def get_setting_label_PrefixSearch(dict_param):\n",
    "    bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "    idx_impl = dict_param['index_impl']\n",
    "    if not bLF and not bPF and idx_impl == 'None': return 'RSS-NAIVE'\n",
    "    elif not bLF and not bPF and idx_impl == 'Naive': return None#return 'RSS-INDEX'\n",
    "    elif not bLF and not bPF and idx_impl == 'Count': return 'RSS-C'\n",
    "    elif not bLF and not bPF and idx_impl == 'Position': return 'RSS-P'\n",
    "    elif bLF and not bPF and idx_impl == 'None': return 'RSS-L'\n",
    "    elif not bLF and bPF and idx_impl == 'None': return 'RSS-R'\n",
    "    \n",
    "    elif not bLF and not bPF and idx_impl == 'CountPosition': return 'RSS-CP'\n",
    "    elif bLF and not bPF and idx_impl == 'Count': return 'RSS-CL'\n",
    "    elif bLF and not bPF and idx_impl == 'Position': return 'RSS-PL'\n",
    "    elif not bLF and bPF and idx_impl == 'Count': return 'RSS-CR'\n",
    "    elif not bLF and bPF and idx_impl == 'Position': return 'RSS-PR'\n",
    "    elif bLF and bPF and idx_impl == 'None': return 'PKDUCK-W'\n",
    "    \n",
    "    elif bLF and not bPF and idx_impl == 'CountPosition': return 'RSS-CPL'\n",
    "    elif not bLF and bPF and idx_impl == 'CountPosition': return 'RSS-CPR'\n",
    "    elif bLF and bPF and idx_impl == 'Count': return 'RSS-CLR'\n",
    "    elif bLF and bPF and idx_impl == 'Position': return 'RSS-PLR'\n",
    "    \n",
    "    elif bLF and bPF and idx_impl == 'CountPosition': return 'RSS-CPLR'\n",
    "    \n",
    "    else: return None\n",
    "\n",
    "def get_setting_label_PkwiseSynSearch(dict_param):\n",
    "    qlen = dict_param['qlen']\n",
    "    kmax = dict_param['kmax']\n",
    "#     if kmax == '1': return 'RSS-PKWISE-k1'\n",
    "#     elif kmax == '2': return 'RSS-PKWISE-k2'\n",
    "    if kmax == 'opt': return 'PKWISE-R'\n",
    "#     if   qlen == '1' and kmax == '1': return 'RSS-PKWISE'\n",
    "#     elif qlen == '3' and kmax == '2': return 'RSS-PKWISE'\n",
    "#     elif qlen == '5' and kmax == '2': return 'RSS-PKWISE'\n",
    "#     elif qlen == '7' and kmax == '2': return 'RSS-PKWISE'\n",
    "#     elif qlen == '9' and kmax == '2': return 'RSS-PKWISE'\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_alg = {}\n",
    "dict_aid = {}\n",
    "with SQLiteContext() as cur:\n",
    "    cur.execute(\"SELECT id, name, version FROM projectManager_algorithm WHERE project_id=1\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows: \n",
    "        dict_alg[row['name']+'_'+row['version']] = row['id']\n",
    "        dict_aid[row['id']] = row['name']+'_'+row['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataInfo = collections.namedtuple('DataInfo', ['name', 'size', 'nr', 'qlen', 'lr', 'nar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "dict_did = {}\n",
    "with SQLiteContext() as cur:\n",
    "    cur.execute(\"SELECT id, name FROM projectManager_dataset WHERE project_id=1 and id >= 498\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        tokens = row['name'].rsplit('_')\n",
    "        if len(tokens) == 5: \n",
    "            dname, size, nr, qlen, lr = tokens\n",
    "            nar = 'a-1'\n",
    "        elif len(tokens) == 6:\n",
    "            dname, size, nr, qlen, lr, nar = tokens\n",
    "        size, nr, qlen, lr, nar = size[1:], nr[1:], qlen[1:], lr[1:], nar[1:]\n",
    "        try: dict_data[dname]\n",
    "        except: dict_data[dname] = {}\n",
    "        dict_data[dname][(size, nr, qlen, lr, nar)] = row['id']\n",
    "        dict_did[row['id']] = (dname, size, nr, qlen, lr, nar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_did_list(data_info):\n",
    "    assert type(data_info) == DataInfo\n",
    "    dname, size, nr, qlen, lr, nar = data_info\n",
    "    const_idx_list = list(map(lambda x:x[0], filter(lambda x: x[1]!='*', enumerate([size, nr, qlen, lr, nar]))))\n",
    "    assert len(const_idx_list) == 4\n",
    "    target_idx = [size, nr, qlen, lr, nar].index('*')\n",
    "    data_item_list = dict_data[dname].items()\n",
    "    for idx in const_idx_list:\n",
    "        data_item_list = list(filter(lambda x: x[0][idx] == data_info[idx+1], data_item_list))\n",
    "    return list(sorted(map(lambda x: (x[0][target_idx], x[1]), data_item_list), key=lambda x:float(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_did_list(dname, nr, qlen, lr, nar):\n",
    "    return list(\n",
    "        sorted(\n",
    "            map(lambda x: (x[0][0], x[1]), \n",
    "                filter(lambda x: x[0][1]==nr and x[0][2]==qlen and x[0][3]==lr, dict_data[dname].items()))\n",
    "        , key=lambda x: int(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qlen_did_list(dname, size, nr, lr, nar):\n",
    "    return list(\n",
    "        sorted(\n",
    "            map(lambda x: (x[0][2], x[1]), \n",
    "                filter(lambda x: x[0][0]==size and x[0][1]==nr and x[0][3]==lr, dict_data[dname].items()))\n",
    "        , key=lambda x: int(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker_list = itertools.cycle(['+', 'x', 'o', '^', 'D', 's', 'v'])\n",
    "marker_list = ['+', 'x', 'o', '^', 'D', 's', 'v']\n",
    "dashes_list = itertools.cycle([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_info(data_info):\n",
    "    assert type(data_info) == DataInfo\n",
    "    dname, size, nr, qlen, lr, nar = data_info\n",
    "    return dname, size, nr, qlen, lr, nar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query_row(row, more_features=None):\n",
    "    aid = int(row['algorithm_id'])\n",
    "    dict_param = str2dict(row['parameter'])\n",
    "    dict_rslt = str2dict(row['result'])\n",
    "    dict_param['qlen'] = dict_rslt['Dataset_qlen']\n",
    "\n",
    "    output = {}\n",
    "    output['id'] = dict_rslt['Alg_ID']\n",
    "    output['nq'] = int(dict_rslt['Dataset_numSearched'])\n",
    "    output['n'] = int(dict_rslt['Dataset_numIndexed'])\n",
    "    try: output['n_doc'] = int(dict_rslt['Dataset_numDoc'])\n",
    "    except: pass\n",
    "    output['nr'] = int(dict_rslt['Dataset_nr'])\n",
    "    output['qlen'] = int(dict_rslt['Dataset_qlen'])\n",
    "    output['lr'] = float(dict_rslt['Dataset_lr'])\n",
    "    try: output['nar'] = float(dict_rslt['Dataset_nar'])\n",
    "    except: output['nar'] = None\n",
    "    output['Dataset_name'] = dict_rslt['Dataset_Name'].split('_')[0]\n",
    "    output['theta'] = float(dict_param['theta'])\n",
    "    output['setting'] = get_setting_label(aid, dict_param)\n",
    "#     if output['setting'] not in setting_list: return None\n",
    "    output['alg'] = dict_aid[aid]\n",
    "    output['label'] = output['alg'] +'_' + output['setting']\n",
    "    output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "    output['Time_QS_Total'] = float(dict_rslt['Time_QS_Total'])/1000\n",
    "    output['Time_TS_Total'] = float(dict_rslt['Time_TS_Total'])/1000\n",
    "    output['Time_Search'] = output['Time_QS_Total'] + output['Time_TS_Total']\n",
    "    output['Time_SearchPerQuery_MEAN'] = float(dict_rslt['Time_SearchPerQuery_MEAN'])/1000\n",
    "    output['Time_IndexFilter'] = (float(dict_rslt['Time_QS_IndexFilter']) + float(dict_rslt['Time_TS_IndexFilter']))/1000\n",
    "    output['Time_Validation'] = (float(dict_rslt['Time_QS_Validation']) + float(dict_rslt['Time_TS_Validation']))/1000\n",
    "    output['Time_BuildIndex'] = float(dict_rslt['Time_BuildIndex'])/1000\n",
    "    output['Num_Result'] = int(dict_rslt['Num_Result'])\n",
    "    output['Num_QS_Verified'] = int(dict_rslt['Num_QS_Verified'])\n",
    "    output['Num_TS_Verified'] = int(dict_rslt['Num_TS_Verified'])\n",
    "    output['Num_Verified'] = output['Num_QS_Verified'] + output['Num_TS_Verified']\n",
    "    output['Len_Retrieved'] = int(dict_rslt['Len_QS_Retrieved']) + int(dict_rslt['Len_TS_Retrieved'])\n",
    "    output['Space_Index'] = int(dict_rslt['Space_Index'])/1e6 if dict_rslt['Space_Index'] != 'null' else 0\n",
    "    \n",
    "    assert more_features is None or type(more_features) == list or more_features == '*'\n",
    "    if more_features is not None:\n",
    "        if more_features == '*': more_features = list(sorted(dict_rslt.keys() - output.keys()))\n",
    "        for feat in more_features:\n",
    "            val = dict_rslt[feat]\n",
    "            try: output[feat] = int(val)\n",
    "            except:\n",
    "                try: output[feat] = float(val)/1000\n",
    "                except: output[feat] = val\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_filtering(data_info, alg_name=alg_name_final):\n",
    "    dname, size, nr, qlen, lr, nar = parse_data_info(data_info)\n",
    "    did = dict_data[dname][(size, nr, qlen, lr, nar)]\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "    query = query_tmpl.format(predicates)\n",
    "    output_list = []\n",
    "    for row in execute_query(query):\n",
    "        dict_param = str2dict(row['parameter'])\n",
    "        dict_rslt = str2dict(row['result'])\n",
    "        output = {}\n",
    "        output['algorithm_id'] = row['algorithm_id']\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "#         bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "#         idx_impl = dict_param['index_impl']\n",
    "        output['setting'] = get_setting_label(output['algorithm_id'], dict_param)\n",
    "        if output['setting'] is None: continue\n",
    "        output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "        output['Time_SearchPerQuery_MEAN'] = float(dict_rslt['Time_SearchPerQuery_MEAN'])/1000\n",
    "        output['Num_QS_Verified'] = int(dict_rslt['Num_QS_Verified'])\n",
    "        output['Num_TS_Verified'] = int(dict_rslt['Num_TS_Verified'])\n",
    "        output['Num_Verified'] = int(dict_rslt['Num_QS_Verified']) + int(dict_rslt['Num_TS_Verified'])\n",
    "        output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_size(data_info, alg_list=alg_list):\n",
    "    size_did_list = get_did_list(data_info)\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    output_list = []\n",
    "    for size, did in size_did_list:\n",
    "        predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "        query = query_tmpl.format(predicates)\n",
    "        for row in execute_query(query):\n",
    "            output = parse_query_row(row)\n",
    "            if output is None: continue\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "#     df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_qlen(data_info, alg_list=alg_list):\n",
    "    qlen_did_list = get_did_list(data_info)\n",
    "    qlen_list = list(map(lambda x:int(x[0]), qlen_did_list))\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    output_list = []\n",
    "    for qlen, did in qlen_did_list:\n",
    "        predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "        query = query_tmpl.format(predicates)\n",
    "        for row in execute_query(query):\n",
    "            output = parse_query_row(row)\n",
    "            if output is None: continue\n",
    "            output['qlen'] = int(qlen)\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "#     df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_nr(data_info, alg_list=alg_list):\n",
    "    nr_did_list = get_did_list(data_info)\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    output_list = []\n",
    "    for nr, did in nr_did_list:\n",
    "        predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "        query = query_tmpl.format(predicates)\n",
    "        for row in execute_query(query):\n",
    "            output = parse_query_row(row)\n",
    "            if output is None: continue\n",
    "            output['nr'] = int(nr)\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "#     df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_lr(data_info, alg_list=alg_list):\n",
    "    lr_did_list = get_did_list(data_info)\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    output_list = []\n",
    "    for lr, did in lr_did_list:\n",
    "        predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "        query = query_tmpl.format(predicates)\n",
    "        for row in execute_query(query):\n",
    "            output = parse_query_row(row)\n",
    "            if output is None: continue\n",
    "            output['lr'] = float(lr)\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "#     df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_acc(alg_name=alg_name_final):\n",
    "    output_list = []\n",
    "    aid = dict_alg[alg_name]\n",
    "    predicates = ' '.join(['AND algorithm_id={}'.format(aid)])\n",
    "    query = query_tmpl.format(predicates)\n",
    "    for row in execute_query(query):\n",
    "        aid = int(row['algorithm_id'])\n",
    "        dict_param = str2dict(row['parameter'])\n",
    "        dict_rslt = str2dict(row['result'])\n",
    "        bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "        idx_impl = dict_param['index_impl']\n",
    "\n",
    "        output = {}\n",
    "        output['data_name'] = dict_rslt['Dataset_Name'].split('_',1)[0]\n",
    "        output['n'] = int(dict_rslt['Dataset_nt'])\n",
    "        output['nr'] = int(dict_rslt['Dataset_nr'])\n",
    "        output['qlen'] = int(dict_rslt['Dataset_qlen'])\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "        output['setting'] = get_setting_label(aid, dict_param)\n",
    "        if output['setting'] is None: continue\n",
    "        output['Num_Result'] = int(dict_rslt['Num_Result'])\n",
    "        output['Num_QS_Result'] = int(dict_rslt['Num_QS_Result'])\n",
    "        output['Num_TS_Result'] = int(dict_rslt['Num_TS_Result'])\n",
    "        output_list.append(output)\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_PrefixSearchFilterPowerTest(setting_list, path='./ZeroPrefixSearch.out'):\n",
    "#     if setting_list is None: setting_list = ['RSS-NAIVE', 'RSS-C', 'RSS-P', 'RSS-L', 'RSS-CP', 'RSS-CL', 'RSS-PL','RSS-CPL', 'RSS-CPR', 'RSS-CPLR']\n",
    "    output_list = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            token_list = line.strip().split('\\t')\n",
    "            row = {k:v for k,v in map(lambda x:x.split(':',1), token_list)}\n",
    "            dict_param = {k:v for k,v in map(lambda x:x.split(':',1), row['Param'][1:-3].split(', '))}\n",
    "            \n",
    "            output = {}\n",
    "            output['theta'] = float(dict_param['theta'])\n",
    "            output['data_name'] = row['Dataset_Name'].split('_',1)[0]\n",
    "            output['n'] = int(row['Dataset_nt'])\n",
    "            output['nr'] = int(row['Dataset_nr'])\n",
    "            output['qlen'] = int(row['Dataset_qlen'])\n",
    "            output['setting'] = get_setting_label(56, dict_param)\n",
    "            output['Num_QS_Verified'] = int(row['Num_QS_Verified'])\n",
    "            output['Num_TS_Verified'] = int(row['Num_TS_Verified'])\n",
    "            output['Num_Verified'] = int(row['Num_QS_Verified']) + int(row['Num_TS_Verified'])\n",
    "            output['Len_Verified'] = int(row['Len_QS_Verified']) + int(row['Len_TS_Verified'])\n",
    "            output['Time_QS_Total'] = float(row['Time_QS_Total'])/1000\n",
    "            output['Time_TS_Total'] = float(row['Time_TS_Total'])/1000\n",
    "            output['Time_Total'] = float(row['Time_Total'])/1000\n",
    "            output['Time_SearchPerQuery_MEAN'] = float(row['Time_SearchPerQuery_MEAN'])/1000\n",
    "            try: output['Time_TS_searchRecordPF.pkduck'] = float(row['Time_TS_searchRecordPF.pkduck'])/1000\n",
    "            except: output['Time_TS_searchRecordPF.pkduck'] = 0\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    dfg = df.groupby(by=['data_name', 'n', 'nr', 'qlen', 'setting', 'theta']).mean().reset_index()\n",
    "    return dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_list = ['RSS-NAIVE', 'RSS-C', 'RSS-P', 'RSS-L', 'RSS-R', 'RSS-CL', 'RSS-PL', 'RSS-CP', 'RSS-CR', 'RSS-PR', 'PKDUCK-W', 'RSS-CPL', 'RSS-CPR', 'RSS-CLR', 'RSS-PLR', 'RSS-CPLR']\n",
    "path = 'ZeroPrefixSearch.out.repeat10'\n",
    "output_list = []\n",
    "with open(path) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        token_list = line.strip().split('\\t')\n",
    "        row = {k:v for k,v in map(lambda x:x.split(':',1), token_list)}\n",
    "        dict_param = {k:v for k,v in map(lambda x:x.split(':',1), row['Param'][1:-3].split(', '))}\n",
    "\n",
    "        output = {}\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "        output['data_name'] = row['Dataset_Name'].split('_',1)[0]\n",
    "        output['n'] = int(row['Dataset_nt'])\n",
    "        output['nr'] = int(row['Dataset_nr'])\n",
    "        output['qlen'] = int(row['Dataset_qlen'])\n",
    "        output['setting'] = get_setting_label(56, dict_param)\n",
    "        output['Num_QS_Verified'] = int(row['Num_QS_Verified'])\n",
    "        output['Num_TS_Verified'] = int(row['Num_TS_Verified'])\n",
    "        output['Num_Verified'] = int(row['Num_QS_Verified']) + int(row['Num_TS_Verified'])\n",
    "        output['Len_Verified'] = int(row['Len_QS_Verified']) + int(row['Len_TS_Verified'])\n",
    "        output['Time_Total'] = float(row['Time_Total'])/1000\n",
    "        output['Time_SearchPerQuery_MEAN'] = float(row['Time_SearchPerQuery_MEAN'])/1000\n",
    "        try: output['Time_TS_searchRecordPF.pkduck'] = float(row['Time_TS_searchRecordPF.pkduck'])/1000\n",
    "        except: output['Time_TS_searchRecordPF.pkduck'] = 0\n",
    "        output_list.append(output)\n",
    "#         if idx > 0: break\n",
    "df = pd.DataFrame.from_dict(output_list)\n",
    "df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "dfg = df.groupby(by=['data_name', 'n', 'qlen', 'setting', 'theta']).mean().reset_index()\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_ExactPrefixSearch():\n",
    "    path = './ExactPrefixSearch.txt'\n",
    "    output_list = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            token_list = line.strip().split('\\t')\n",
    "            row = {k:v for k,v in map(lambda x:x.split(':',1), token_list)}\n",
    "            dict_param = {k:v for k,v in map(lambda x:x.split(':',1), row['Param'][1:-3].split(', '))}\n",
    "            output = {}\n",
    "            output['theta'] = float(dict_param['theta'])\n",
    "            output['data_name'] = row['Dataset_Name'].split('_',1)[0]\n",
    "            output['n'] = int(row['Dataset_nt'])\n",
    "            output['nr'] = int(row['Dataset_nr'])\n",
    "            output['qlen'] = int(row['Dataset_qlen'])\n",
    "            output['Num_QS_Result'] = int(row['Num_QS_Result'])\n",
    "            output['Num_TS_Result'] = int(row['Num_TS_Result'])\n",
    "            output['Num_Result'] = int(row['Num_Result'])\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_index_stat(data_info, alg_list=alg_list):\n",
    "    dname, size, nr, qlen, lr = parse_data_info(data_info)\n",
    "    did = dict_data[dname][(size, nr, qlen, lr)]\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "    query = query_tmpl.format(predicates)\n",
    "    output_list = []\n",
    "    for row in execute_query(query):\n",
    "        aid = int(row['algorithm_id'])\n",
    "        dict_param = str2dict(row['parameter'])\n",
    "        dict_rslt = str2dict(row['result'])\n",
    "\n",
    "        output = {}\n",
    "        output['data_name'] = dict_rslt['Dataset_Name'].split('_',1)[0]\n",
    "        output['n'] = int(dict_rslt['Dataset_nt'])\n",
    "        output['nr'] = int(dict_rslt['Dataset_nr'])\n",
    "        output['qlen'] = int(dict_rslt['Dataset_qlen'])\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "        output['setting'] = get_setting_label(aid, dict_param)\n",
    "        if output['setting'] is None: continue\n",
    "        output['Time_BuildIndex'] = float(dict_rslt['Time_BuildIndex'])/1000\n",
    "        output['Space_Index'] = 0 if dict_rslt['Space_Index'] == 'null' else int(dict_rslt['Space_Index'])\n",
    "        output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_verify_by_filtering(theta, qlen):\n",
    "    df = df_from_PrefixSearchFilterPowerTest()\n",
    "    df = df[df.theta == float(theta)][df.qlen == int(qlen)]\n",
    "    f, axes = plt.subplots(1, 3, figsize=(21, 6), sharex=True, sharey=False)\n",
    "    sb.catplot(x='setting', y='Num_Verified', hue='setting', data=df[df.data_name == 'WIKI'], kind='bar', ax=axes[0])\n",
    "    sb.catplot(x='setting', y='Num_Verified', hue='setting', data=df[df.data_name == 'PUBMED'], kind='bar', ax=axes[1])\n",
    "    sb.catplot(x='setting', y='Num_Verified', hue='setting', data=df[df.data_name == 'AMAZON'], kind='bar', ax=axes[2])\n",
    "    axes[0].set(ylabel='# Verified', yscale='log')\n",
    "    axes[1].set(ylabel='# Verified', yscale='log')\n",
    "    axes[2].set(ylabel='# Verified', yscale='log')\n",
    "    for i in range(2,5): plt.close(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_filtering(data_info, alg_name=alg_name_final):\n",
    "    df = df_time_by_filtering(data_info, alg_name=alg_name_final)\n",
    "    f, axes = plt.subplots(1, 3, figsize=(21, 6), sharex=False, sharey=False)\n",
    "    sb.catplot(x='theta', y='Time_Total', hue='setting', data=df, kind='bar', ax=axes[0])\n",
    "    sb.catplot(x='theta', y='Time_SearchPerQuery_MEAN', hue='setting', data=df, kind='bar', ax=axes[1])\n",
    "    sb.catplot(x='theta', y='Num_Verified', hue='setting', data=df, kind='bar', ax=axes[2])\n",
    "    axes[0].set(ylabel='Total Time (sec)', yscale='log')\n",
    "    axes[1].set(ylabel='Mean query time (s)', yscale='log')\n",
    "    axes[2].set(ylabel='# Verified', yscale='log')\n",
    "    for i in range(2,5): plt.close(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_hue_style_orders(df):\n",
    "#     counter = {'setting':Counter(), 'alg':Counter()}\n",
    "#     for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "#         for val in set(df[df.theta==theta]['setting']): counter['setting'][val] += 1\n",
    "#         for val in set(df[df.theta==theta]['alg']): counter['alg'][val] += 1\n",
    "#     hue_order = list(sorted(counter['setting'].keys(), key=counter['setting'].get, reverse=True))\n",
    "#     style_order = list(sorted(counter['alg'].keys(), key=counter['alg'].get, reverse=True))\n",
    "#     return hue_order, style_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_size(data_info, alg_list=alg_list, setting_list=setting_list, y='Time_SearchPerQuery_MEAN', ylabel='Mean query time (s)', theta_list=[0.6, 0.7, 0.8, 0.9, 1.0], savefig=False):\n",
    "    df = df_time_by_size(data_info, alg_list=alg_list)\n",
    "    f, axes = plt.subplots(1, len(theta_list), figsize=(5*len(theta_list), 5), sharex=False, sharey=False, squeeze=False)\n",
    "    f.suptitle(data_info)\n",
    "    x = \"n_doc\" if data_info.name.endswith('-DOC') else \"n\"\n",
    "    for i, theta in enumerate(theta_list):\n",
    "        ax = axes[0][i]\n",
    "        sb.lineplot(data=df[df.theta==theta], x=x, y=y, hue=\"setting\", hue_order=setting_list, style=\"alg\", style_order=alg_list, markers=True, alpha=0.3, ax=ax)\n",
    "        ax.set(ylabel=ylabel, xscale='log', yscale='log', title='theta=%.1f'%theta)\n",
    "        if i == len(theta_list)-1: ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        else: ax.get_legend().remove()\n",
    "    if savefig: plt.savefig(f'plot_time_by_size_{data_info.name}.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_qlen(data_info, alg_list=alg_list, y='Time_SearchPerQuery_MEAN', ylabel='Mean query time (s)', savefig=False):\n",
    "    dname, size, nr, qlen, lr, nar = parse_data_info(data_info)\n",
    "    qlen_list = list(map(lambda x:int(x[0]), get_did_list(data_info)))\n",
    "    df = df_time_by_qlen(data_info, alg_list=alg_list)\n",
    "    f, axes = plt.subplots(1, 5, figsize=(25, 5), sharex=False, sharey=False)\n",
    "    for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "        sb.lineplot(data=df[df.theta==theta], x=\"qlen\", y=y, hue=\"setting\", hue_order=setting_list, style=\"alg\", style_order=alg_list, markers=True, ax=axes[i])\n",
    "        axes[i].set(xticks=qlen_list, ylabel=ylabel, yscale='log', title='theta=%.1f'%theta)\n",
    "        if i == 4: axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        else: axes[i].get_legend().remove()\n",
    "    if savefig: plt.savefig(f'plot_time_by_qlen_{data_info.name}.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_nr(data_info, alg_list=alg_list, y='Time_SearchPerQuery_MEAN', ylabel='Mean query time (s)', savefig=False):\n",
    "    df = df_time_by_nr(data_info, alg_list=alg_list)\n",
    "    f, axes = plt.subplots(1, 5, figsize=(25, 5), sharex=False, sharey=False)\n",
    "    for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "        sb.lineplot(data=df[df.theta==theta], x=\"nr\", y=y, hue=\"setting\", hue_order=setting_list, style=\"alg\", style_order=alg_list, markers=True, ax=axes[i])\n",
    "        axes[i].set(ylabel=ylabel, xscale='log', yscale='log', title='theta=%.1f'%theta)\n",
    "        if i == 4: axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        else: axes[i].get_legend().remove()\n",
    "    if savefig: plt.savefig(f'plot_time_by_nr_{data_info.name}.png', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_lr(data_info, alg_list=alg_list, y='Time_SearchPerQuery_MEAN', ylabel='Mean query time (s)'):\n",
    "    df = df_time_by_lr(data_info, alg_list=alg_list)\n",
    "    lr_list = list(map(lambda x:float(x[0]), get_did_list(data_info)))\n",
    "    f, axes = plt.subplots(1, 5, figsize=(25, 5), sharex=False, sharey=False)\n",
    "    for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "        sb.lineplot(data=df[df.theta==theta], x=\"lr\", y=y, hue=\"setting\", hue_order=setting_list, style=\"alg\", style_order=alg_list, markers=True, ax=axes[i])\n",
    "        axes[i].set(xticks=lr_list, ylabel=ylabel, yscale='log', title='theta=%.1f'%theta)\n",
    "        if i == 4: axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        else: axes[i].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_alg(alg0_name, alg1_name):\n",
    "    aid0 = dict_alg[alg0_name]\n",
    "    aid1 = dict_alg[alg1_name]\n",
    "    predicates = ' '.join(['AND (algorithm_id={} OR algorithm_id={})'.format(aid0, aid1)])\n",
    "    query = query_tmpl.format(predicates)\n",
    "    output_list = []\n",
    "    for row in execute_query(query):\n",
    "        dict_param = str2dict(row['parameter'])\n",
    "        dict_rslt = str2dict(row['result'])\n",
    "        bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "        idx_impl = dict_param['index_impl']\n",
    "\n",
    "        output = {}\n",
    "        output['dataset'] = dict_rslt['Dataset_Name']\n",
    "        output['size'] = dict_rslt['Dataset_Name']\n",
    "        output['alg'] = dict_rslt['Alg_Name']+'_'+dict_rslt['Alg_Version']\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "        output['setting'] = get_setting_label(aid0, dict_param)\n",
    "        if output['setting'] is None: continue\n",
    "        output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "        try: output['Time_QS_Total'] = float(dict_rslt['Time_QS_Total'])/1000\n",
    "        except: output['Time_QS_Total'] = float(dict_rslt['Time_QS_Total'])/1000\n",
    "        try: output['Time_TS_Total'] = float(dict_rslt['Time_TS_Total'])/1000\n",
    "        except: output['Time_TS_Total'] = float(dict_rslt['Time_TS_Total'])/1000\n",
    "        output['Time_Search'] = output['Time_QS_Total'] + output['Time_TS_Total']\n",
    "        output['Num_Verified'] = int(dict_rslt['Num_QS_Verified']) + int(dict_rslt['Num_TS_Verified'])\n",
    "        output['Num_QS_Result'] = int(dict_rslt['Num_QS_Result'])\n",
    "        output['Num_TS_Result'] = int(dict_rslt['Num_TS_Result'])\n",
    "        \n",
    "        output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "#     df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    \n",
    "    df0 = df[df.alg==alg0_name].drop(['alg'], axis=1)\n",
    "    df1 = df[df.alg==alg1_name].drop(['alg'], axis=1)\n",
    "    df_merged = pd.merge(df0, df1, on=['dataset', 'size', 'theta', 'setting'], how='inner', suffixes=['_0','_1'])\n",
    "    df_merged['diff_Time'] = df_merged['Time_Total_1'] - df_merged['Time_Total_0']\n",
    "#     df_merged['diff_Time_ratio'] = (df_merged['Time_Total_1'] - df_merged['Time_Total_0'])/df_merged['Time_Total_0']\n",
    "    df_merged['diff_Time_Search'] = df_merged['Time_Search_1'] - df_merged['Time_Search_0']\n",
    "#     df_merged['diff_Time_Search_ratio'] = (df_merged['Time_Search_1'] - df_merged['Time_Search_0'])/df_merged['Time_Search_0']\n",
    "    df_merged['diff_Verify'] = df_merged['Num_Verified_1'] - df_merged['Num_Verified_0']\n",
    "#     df_merged['diff_Verify_ratio'] = (df_merged['Num_Verified_1'] - df_merged['Num_Verified_0'])/df_merged['Num_Verified_0']\n",
    "    df_merged['diff_QS_Result'] = df_merged['Num_QS_Result_1'] - df_merged['Num_QS_Result_0']\n",
    "    df_merged['diff_TS_Result'] = df_merged['Num_TS_Result_1'] - df_merged['Num_TS_Result_0']\n",
    "    print('diff_Time:',df_merged['diff_Time'].mean())\n",
    "#     print('diff_Time_ratio:',df_merged['diff_Time_ratio'].mean())\n",
    "    print('diff_Time_Search:',df_merged['diff_Time_Search'].mean())\n",
    "#     print('diff_Time_Search_ratio:',df_merged['diff_Time_Search_ratio'].mean())\n",
    "    print('diff_Verify:',df_merged['diff_Verify'].mean())\n",
    "#     print('diff_Verify_ratio:',df_merged['diff_Verify_ratio'].mean())\n",
    "    print('diff_QS_Result:',df_merged['diff_QS_Result'].mean())\n",
    "    print('diff_TS_Result:',df_merged['diff_TS_Result'].mean())\n",
    "    df_merged = df_merged.reindex(sorted(df_merged.columns), axis=1)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def performance_comparison():\n",
    "    \n",
    "#     def compare_algs(df, alg0, alg1, data_info=None, measure='Time_SearchPerQuery_MEAN'):\n",
    "#         vals0 = df[df.setting==alg0][measure].values\n",
    "#         vals1 = df[df.setting==alg1][measure].values\n",
    "#         n = min(len(vals0), len(vals1))\n",
    "#         print(measure, '' if data_info is None else data_info.name, '{}/{}'.format(alg0, alg1), vals0[:n]/vals1[:n])\n",
    "    \n",
    "#     df = df_from_PrefixSearchFilterPowerTest()\n",
    "#     df = df[df.theta==theta0][df.n==n0][df.qlen==qlen0]\n",
    "#     compare_algs(df, 'IF', 'NaivePF', measure='Num_Verified')\n",
    "#     compare_algs(df, 'IF', 'ICF', measure='Num_Verified')\n",
    "#     compare_algs(df, 'IF', 'IPF', measure='Num_Verified')\n",
    "    \n",
    "#     for data_info in [DataInfo('WIKI', '*', '107836', '3')]:#, DataInfo('PUBMED', '*', '79011', '3'), DataInfo('AMAZON', '*', '107836', '3')]:\n",
    "#         df = df_time_by_size(data_info)\n",
    "#         df = df[df.theta==theta0]\n",
    "#         for setting in ['IPF', 'LF', 'PF']:\n",
    "#             compare_algs(df, 'ICF', setting)\n",
    "#         compare_algs(df, 'NaivePF', 'PF')\n",
    "#         compare_algs(df, 'IF', 'NaivePF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_heuristic_accuracy():\n",
    "    df0 = df_from_ExactPrefixSearch()\n",
    "    df1 = df_acc()\n",
    "    df = df0.merge(df1, on=['data_name', 'n', 'nr', 'qlen', 'theta'], suffixes=['0',''], how='inner')\n",
    "    df = df[['data_name', 'n', 'nr', 'qlen', 'theta', 'setting', 'Num_Result0', 'Num_Result', 'Num_QS_Result0', 'Num_QS_Result', 'Num_TS_Result0', 'Num_TS_Result']]\n",
    "    df['Acc'] = df['Num_Result']/df['Num_Result0']\n",
    "    df['Acc_QS'] = df['Num_QS_Result']/df['Num_QS_Result0']\n",
    "    df['Acc_TS'] = df['Num_TS_Result']/df['Num_TS_Result0']\n",
    "\n",
    "    df = df[df.n==10000][df.nr==31622][df.setting=='RSS-CPL']\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
