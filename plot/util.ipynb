{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import collections\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLiteContext:\n",
    "    def __init__(self):\n",
    "        self.conn = sqlite3.connect('/home/ghsong/django-substring/mysite/db.sqlite3')\n",
    "        self.conn.row_factory = dict_factory\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self.conn.cursor()\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query):\n",
    "    with SQLiteContext() as cur:\n",
    "        cur.execute(query)\n",
    "        return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tmpl = 'SELECT exp_date, algorithm_id, dataset_id, parameter, result FROM projectManager_expitem WHERE project_id=1 {} ORDER BY -exp_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_factory(cursor, row):\n",
    "    d = {}\n",
    "    for idx, col in enumerate(cursor.description):\n",
    "        d[col[0]] = row[idx]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2dict(s):\n",
    "    return ast.literal_eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting_list = ['LSS-NAIVE', 'LSS-L+PR', 'LSS-C', 'LSS-C+P', 'LSS-C+P+L', 'LSS-C+P+L+PR', 'LSS-PKWISE']#, 'LSS-PKWISE2', 'LSS-PKWISE3']\n",
    "# setting_list = ['LSS-NAIVE', 'LSS-C', 'LSS-P', 'LSS-L', 'LSS-PR', 'LSS-C+P', 'LSS-C+L', 'LSS-P+L','LSS-C+P+L', 'LSS-C+P+L+PR']\n",
    "# setting_list = ['LSS-NAIVE', 'LSS-C', 'LSS-P', 'LSS-L',  'LSS-C+P', 'LSS-C+L', 'LSS-P+L','LSS-C+P+L', 'LSS-C+P+PR', 'LSS-C+P+L+PR']\n",
    "setting_list = ['LSS-NAIVE', 'LSS-C', 'LSS-P', 'LSS-C+P', 'LSS-C+L', 'LSS-P+L', 'LSS-C+P+L']\n",
    "\n",
    "def get_setting_label(aid, dict_param):\n",
    "#     print(aid, dict_param)\n",
    "    if aid == 28: # PrefixSearch_6.20\n",
    "        return get_setting_label_PrefixSearch(dict_param)\n",
    "    elif aid == 31: # PkwiseSynSearch_1.02\n",
    "        return get_setting_label_PkwiseSynSearch(dict_param)\n",
    "    \n",
    "def get_setting_label_PrefixSearch(dict_param):\n",
    "    bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "    idx_impl = dict_param['index_impl']\n",
    "    if not bLF and not bPF and idx_impl == 'None': return 'LSS-NAIVE'\n",
    "    elif not bLF and not bPF and idx_impl == 'Naive': return None#return 'LSS-INDEX'\n",
    "    elif not bLF and not bPF and idx_impl == 'Count': return 'LSS-C'\n",
    "    elif not bLF and not bPF and idx_impl == 'PositionOnly': return 'LSS-P'\n",
    "    elif bLF and not bPF and idx_impl == 'Naive': return 'LSS-L'\n",
    "    elif not bLF and bPF and idx_impl == 'Naive': return 'LSS-PR'\n",
    "    \n",
    "    elif not bLF and not bPF and idx_impl == 'Position': return 'LSS-C+P'\n",
    "    elif bLF and not bPF and idx_impl == 'Count': return 'LSS-C+L'\n",
    "    elif bLF and not bPF and idx_impl == 'PositionOnly': return 'LSS-P+L'\n",
    "    \n",
    "    elif bLF and not bPF and idx_impl == 'Position': return 'LSS-C+P+L'\n",
    "    elif not bLF and bPF and idx_impl == 'Position': return 'LSS-C+P+PR'    \n",
    "    elif bLF and bPF and idx_impl == 'Position': return 'LSS-C+P+L+PR'\n",
    "    \n",
    "    elif bLF and bPF and idx_impl == 'Naive': return 'LSS-L+PR'\n",
    "    else: return None\n",
    "\n",
    "def get_setting_label_PkwiseSynSearch(dict_param):\n",
    "    qlen = dict_param['qlen']\n",
    "    kmax = dict_param['kmax']\n",
    "    if   qlen == '1' and kmax == '1': return 'LSS-PKWISE'\n",
    "    elif qlen == '3' and kmax == '2': return 'LSS-PKWISE'\n",
    "    elif qlen == '5' and kmax == '2': return 'LSS-PKWISE'\n",
    "    elif qlen == '7' and kmax == '2': return 'LSS-PKWISE'\n",
    "    elif qlen == '9' and kmax == '2': return 'LSS-PKWISE'\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_list = ['PrefixSearch_6.20', 'PkwiseSynSearch_1.02']\n",
    "# alg_list = ['PrefixSearch_6.20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_alg = {}\n",
    "dict_aid = {}\n",
    "with SQLiteContext() as cur:\n",
    "    cur.execute(\"SELECT id, name, version FROM projectManager_algorithm WHERE project_id=1\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows: \n",
    "        dict_alg[row['name']+'_'+row['version']] = row['id']\n",
    "        dict_aid[row['id']] = row['name']+'_'+row['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataInfo = collections.namedtuple('DataInfo', ['name', 'size', 'nr', 'qlen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "dict_did = {}\n",
    "with SQLiteContext() as cur:\n",
    "    cur.execute(\"SELECT id, name FROM projectManager_dataset WHERE project_id=1 and id >= 71\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows: \n",
    "        dname, size, nr, qlen = row['name'].rsplit('_', 3)\n",
    "        size, nr, qlen = size[1:], nr[1:], qlen[1:]\n",
    "        try: dict_data[dname]\n",
    "        except: dict_data[dname] = {}\n",
    "        dict_data[dname][(size, nr, qlen)] = row['id']\n",
    "        dict_did[row['id']] = (dname, size, nr, qlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_did_list(data_info):\n",
    "    assert type(data_info) == DataInfo\n",
    "    dname, size, nr, qlen = data_info\n",
    "    const_idx_list = list(map(lambda x:x[0], filter(lambda x: x[1]!='*', enumerate([size, nr, qlen]))))\n",
    "    assert len(const_idx_list) == 2\n",
    "    target_idx = [size, nr, qlen].index('*')\n",
    "    data_item_list = dict_data[dname].items()\n",
    "    for idx in const_idx_list:\n",
    "        data_item_list = list(filter(lambda x: x[0][idx] == data_info[idx+1], data_item_list))\n",
    "    return list(sorted(map(lambda x: (x[0][target_idx], x[1]), data_item_list), key=lambda x:int(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_did_list(dname, nr, qlen):\n",
    "    return list(\n",
    "        sorted(\n",
    "            map(lambda x: (x[0][0], x[1]), \n",
    "                filter(lambda x: x[0][1]==nr and x[0][2]==qlen, dict_data[dname].items()))\n",
    "        , key=lambda x: int(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qlen_did_list(dname, size, nr):\n",
    "    return list(\n",
    "        sorted(\n",
    "            map(lambda x: (x[0][2], x[1]), \n",
    "                filter(lambda x: x[0][0]==size and x[0][1]==nr, dict_data[dname].items()))\n",
    "        , key=lambda x: int(x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marker_list = itertools.cycle(['+', 'x', 'o', '^', 'D', 's', 'v'])\n",
    "marker_list = ['+', 'x', 'o', '^', 'D', 's', 'v']\n",
    "dashes_list = itertools.cycle([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_info(data_info):\n",
    "    assert type(data_info) == DataInfo\n",
    "    dname, size, nr, qlen = data_info\n",
    "    return dname, size, nr, qlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_filtering(data_info, alg_name=alg_name_final):\n",
    "    dname, size, nr, qlen = parse_data_info(data_info)\n",
    "    did = dict_data[dname][(size, nr, qlen)]\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "    query = query_tmpl.format(predicates)\n",
    "    output_list = []\n",
    "    for row in execute_query(query):\n",
    "        dict_param = str2dict(row['parameter'])\n",
    "        dict_rslt = str2dict(row['result'])\n",
    "        output = {}\n",
    "        output['algorithm_id'] = row['algorithm_id']\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "#         bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "#         idx_impl = dict_param['index_impl']\n",
    "        output['setting'] = get_setting_label(output['algorithm_id'], dict_param)\n",
    "        if output['setting'] is None: continue\n",
    "        output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "        output['Time_SearchPerQuery_MEAN'] = float(dict_rslt['Time_SearchPerQuery_MEAN'])/1000\n",
    "        output['Num_QS_Verified'] = int(dict_rslt['Num_QS_Verified'])\n",
    "        output['Num_TS_Verified'] = int(dict_rslt['Num_TS_Verified'])\n",
    "        output['Num_Verified'] = int(dict_rslt['Num_QS_Verified']) + int(dict_rslt['Num_TS_Verified'])\n",
    "        output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_size(data_info, alg_list=alg_list):\n",
    "    dname, size, nr, qlen = parse_data_info(data_info)\n",
    "    size_did_list = get_did_list(data_info)\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    output_list = []\n",
    "    for size, did in size_did_list:\n",
    "        predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "        query = query_tmpl.format(predicates)\n",
    "        for row in execute_query(query):\n",
    "            aid = int(row['algorithm_id'])\n",
    "            dict_param = str2dict(row['parameter'])\n",
    "            dict_rslt = str2dict(row['result'])\n",
    "            dict_param['qlen'] = dict_rslt['Dataset_qlen']\n",
    "\n",
    "            output = {}\n",
    "            output['n'] = int(dict_rslt['Dataset_numIndexed'])\n",
    "            output['theta'] = float(dict_param['theta'])\n",
    "            output['setting'] = get_setting_label(aid, dict_param)\n",
    "            if output['setting'] is None: continue\n",
    "            output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "            try: output['Time_QS_Total'] = float(dict_rslt['Time_QSTotal'])/1000\n",
    "            except: output['Time_QS_Total'] = float(dict_rslt['Time_QS_Total'])/1000\n",
    "            try: output['Time_TS_Total'] = float(dict_rslt['Time_TSTotal'])/1000\n",
    "            except: output['Time_TS_Total'] = float(dict_rslt['Time_TS_Total'])/1000\n",
    "            output['Time_SearchPerQuery_MEAN'] = float(dict_rslt['Time_SearchPerQuery_MEAN'])/1000\n",
    "            output['Time_BuildIndex'] = float(dict_rslt['Time_BuildIndex'])/1000\n",
    "            output['Num_Verified'] = int(dict_rslt['Num_QS_Verified']) + int(dict_rslt['Num_TS_Verified'])\n",
    "            output['Num_Result'] = int(dict_rslt['Num_Result'])\n",
    "            output['Num_QS_Verified'] = int(dict_rslt['Num_QS_Verified'])\n",
    "            output['Num_TS_Verified'] = int(dict_rslt['Num_TS_Verified'])\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_qlen(data_info, alg_list=alg_list):\n",
    "    dname, size, nr, qlen = parse_data_info(data_info)\n",
    "    qlen_did_list = get_did_list(data_info)\n",
    "    qlen_list = list(map(lambda x:int(x[0]), qlen_did_list))\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    output_list = []\n",
    "    for qlen, did in qlen_did_list:\n",
    "        predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "        query = query_tmpl.format(predicates)\n",
    "        for row in execute_query(query):\n",
    "            aid = int(row['algorithm_id'])\n",
    "            dict_param = str2dict(row['parameter'])\n",
    "            dict_rslt = str2dict(row['result'])\n",
    "            dict_param['qlen'] = dict_rslt['Dataset_qlen']\n",
    "\n",
    "            output = {}\n",
    "            output['qlen'] = int(qlen)\n",
    "            output['theta'] = float(dict_param['theta'])\n",
    "            output['setting'] = get_setting_label(aid, dict_param)\n",
    "            if output['setting'] is None: continue\n",
    "            output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "            try: output['Time_QS_Total'] = float(dict_rslt['Time_QSTotal'])/1000\n",
    "            except: output['Time_QS_Total'] = float(dict_rslt['Time_QS_Total'])/1000\n",
    "            try: output['Time_TS_Total'] = float(dict_rslt['Time_TSTotal'])/1000\n",
    "            except: output['Time_TS_Total'] = float(dict_rslt['Time_TS_Total'])/1000\n",
    "            output['Time_SearchPerQuery_MEAN'] = float(dict_rslt['Time_SearchPerQuery_MEAN'])/1000\n",
    "            output['Time_IndexFilter'] = float(dict_rslt['Time_QS_IndexFilter']) + float(dict_rslt['Time_TS_IndexFilter'])\n",
    "            output['Time_Validation'] = float(dict_rslt['Time_QS_Validation']) + float(dict_rslt['Time_TS_Validation'])\n",
    "            output['Num_Result'] = int(dict_rslt['Num_Result'])\n",
    "            output['Num_Verified'] = int(dict_rslt['Num_QS_Verified']) + int(dict_rslt['Num_TS_Verified'])\n",
    "            output['Num_QS_Verified'] = int(dict_rslt['Num_QS_Verified'])\n",
    "            output['Num_TS_Verified'] = int(dict_rslt['Num_TS_Verified'])\n",
    "            output['Len_Retrieved'] = int(dict_rslt['Len_QS_Retrieved']) + int(dict_rslt['Len_TS_Retrieved'])\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_time_by_nr(data_info, alg_list=alg_list):\n",
    "    assert type(data_info) == DataInfo\n",
    "    dname, size, nr, qlen = data_info\n",
    "    nr_did_list = get_did_list(data_info)\n",
    "    predicates_alg = ' OR '.join(['algorithm_id={}'.format(dict_alg[alg_name]) for alg_name in alg_list])\n",
    "    output_list = []\n",
    "    for nr, did in nr_did_list:\n",
    "        predicates = ' AND '.join(['', 'dataset_id={}'.format(did), '({})'.format(predicates_alg)])\n",
    "        query = query_tmpl.format(predicates)\n",
    "        for row in execute_query(query):\n",
    "            aid = int(row['algorithm_id'])\n",
    "            dict_param = str2dict(row['parameter'])\n",
    "            dict_rslt = str2dict(row['result'])\n",
    "            dict_param['qlen'] = dict_rslt['Dataset_qlen']\n",
    "\n",
    "            output = {}\n",
    "            output['nr'] = int(nr)\n",
    "            output['theta'] = float(dict_param['theta'])\n",
    "            output['setting'] = get_setting_label(aid, dict_param)\n",
    "            if output['setting'] is None: continue\n",
    "            output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "            output['Time_SearchPerQuery_MEAN'] = float(dict_rslt['Time_SearchPerQuery_MEAN'])/1000\n",
    "            output['Time_BuildIndex'] = float(dict_rslt['Time_BuildIndex'])/1000\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_acc(alg_name=alg_name_final):\n",
    "    output_list = []\n",
    "    aid = dict_alg[alg_name]\n",
    "    predicates = ' '.join(['AND algorithm_id={}'.format(aid)])\n",
    "    query = query_tmpl.format(predicates)\n",
    "    for row in execute_query(query):\n",
    "        aid = int(row['algorithm_id'])\n",
    "        dict_param = str2dict(row['parameter'])\n",
    "        dict_rslt = str2dict(row['result'])\n",
    "        bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "        idx_impl = dict_param['index_impl']\n",
    "\n",
    "        output = {}\n",
    "        output['data_name'] = dict_rslt['Dataset_Name'].split('_',1)[0]\n",
    "        output['n'] = int(dict_rslt['Dataset_nt'])\n",
    "        output['nr'] = int(dict_rslt['Dataset_nr'])\n",
    "        output['qlen'] = int(dict_rslt['Dataset_qlen'])\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "        output['setting'] = get_setting_label(aid, dict_param)\n",
    "        if output['setting'] is None: continue\n",
    "        output['Num_Result'] = int(dict_rslt['Num_Result'])\n",
    "        output['Num_QS_Result'] = int(dict_rslt['Num_QS_Result'])\n",
    "        output['Num_TS_Result'] = int(dict_rslt['Num_TS_Result'])\n",
    "        output_list.append(output)\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_PrefixSearchFilterPowerTest():\n",
    "    setting_list = ['LSS-NAIVE', 'LSS-C', 'LSS-P', 'LSS-L', 'LSS-PR', 'LSS-C+P', 'LSS-C+L', 'LSS-P+L','LSS-C+P+L', 'LSS-C+P+L+PR']\n",
    "    path = '../tmp/PrefixSearchFilterPowerTest.txt'\n",
    "    output_list = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            token_list = line.strip().split('\\t')\n",
    "            row = {k:v for k,v in map(lambda x:x.split(':',1), token_list)}\n",
    "            dict_param = {k:v for k,v in map(lambda x:x.split(':',1), row['Param'][1:-3].split(', '))}\n",
    "            \n",
    "            output = {}\n",
    "            output['theta'] = float(dict_param['theta'])\n",
    "            output['data_name'] = row['Dataset_Name'].split('_',1)[0]\n",
    "            output['n'] = int(row['Dataset_nt'])\n",
    "            output['nr'] = int(row['Dataset_nr'])\n",
    "            output['qlen'] = int(row['Dataset_qlen'])\n",
    "            output['setting'] = get_setting_label(28, dict_param)\n",
    "            output['Num_QS_Verified'] = int(row['Num_QS_Verified'])\n",
    "            output['Num_TS_Verified'] = int(row['Num_TS_Verified'])\n",
    "            output['Num_Verified'] = int(row['Num_QS_Verified']) + int(row['Num_TS_Verified'])\n",
    "            output['Time_Total'] = float(row['Time_Total'])/1000\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=setting_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_ExactPrefixSearch():\n",
    "    path = '../tmp/ExactPrefixSearch.txt'\n",
    "    output_list = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            token_list = line.strip().split('\\t')\n",
    "            row = {k:v for k,v in map(lambda x:x.split(':',1), token_list)}\n",
    "            dict_param = {k:v for k,v in map(lambda x:x.split(':',1), row['Param'][1:-3].split(', '))}\n",
    "            output = {}\n",
    "            output['theta'] = float(dict_param['theta'])\n",
    "            output['data_name'] = row['Dataset_Name'].split('_',1)[0]\n",
    "            output['n'] = int(row['Dataset_nt'])\n",
    "            output['nr'] = int(row['Dataset_nr'])\n",
    "            output['qlen'] = int(row['Dataset_qlen'])\n",
    "            output['Num_QS_Result'] = int(row['Num_QS_Result'])\n",
    "            output['Num_TS_Result'] = int(row['Num_TS_Result'])\n",
    "            output['Num_Result'] = int(row['Num_Result'])\n",
    "            output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_verify_by_filtering(theta, qlen):\n",
    "    df = df_from_PrefixSearchFilterPowerTest()\n",
    "    df = df[df.theta == float(theta)][df.qlen == int(qlen)]\n",
    "    f, axes = plt.subplots(1, 3, figsize=(21, 6), sharex=True, sharey=False)\n",
    "    sb.catplot(x='setting', y='Num_Verified', hue='setting', data=df[df.data_name == 'WIKI'], kind='bar', ax=axes[0])\n",
    "    sb.catplot(x='setting', y='Num_Verified', hue='setting', data=df[df.data_name == 'PUBMED'], kind='bar', ax=axes[1])\n",
    "    sb.catplot(x='setting', y='Num_Verified', hue='setting', data=df[df.data_name == 'AMAZON'], kind='bar', ax=axes[2])\n",
    "    axes[0].set(ylabel='# Verified', yscale='log')\n",
    "    axes[1].set(ylabel='# Verified', yscale='log')\n",
    "    axes[2].set(ylabel='# Verified', yscale='log')\n",
    "    for i in range(2,5): plt.close(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_filtering(data_info, alg_name=alg_name_final):\n",
    "    df = df_time_by_filtering(data_info, alg_name=alg_name_final)\n",
    "    f, axes = plt.subplots(1, 3, figsize=(21, 6), sharex=False, sharey=False)\n",
    "    sb.catplot(x='theta', y='Time_Total', hue='setting', data=df, kind='bar', ax=axes[0])\n",
    "    sb.catplot(x='theta', y='Time_SearchPerQuery_MEAN', hue='setting', data=df, kind='bar', ax=axes[1])\n",
    "    sb.catplot(x='theta', y='Num_Verified', hue='setting', data=df, kind='bar', ax=axes[2])\n",
    "    axes[0].set(ylabel='Total Time (sec)', yscale='log')\n",
    "    axes[1].set(ylabel='Mean query time (s)', yscale='log')\n",
    "    axes[2].set(ylabel='# Verified', yscale='log')\n",
    "    for i in range(2,5): plt.close(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_size(data_info, alg_list=alg_list, y='Time_SearchPerQuery_MEAN', ylabel='Mean query time (s)'):\n",
    "    df = df_time_by_size(data_info, alg_list=alg_list)\n",
    "    f, axes = plt.subplots(1, 5, figsize=(25, 5), sharex=False, sharey=False)\n",
    "#     for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "#         sb.lineplot(data=df[df.theta==theta], x=\"n\", y=\"Time_Total\", hue=\"setting\", marker='o', ax=axes[0,i])\n",
    "#         axes[0,i].set(ylabel='Total Time (sec)', xscale='log', yscale='log')\n",
    "    for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "        sb.lineplot(data=df[df.theta==theta], x=\"n\", y=y, hue=\"setting\", marker='o', ax=axes[i])\n",
    "        axes[i].set(ylabel=ylabel, xscale='log', yscale='log', title='theta=%.1f'%theta)\n",
    "        if i == 4: axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        else: axes[i].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_qlen(data_info, alg_list=alg_list, y='Time_SearchPerQuery_MEAN', ylabel='Mean query time (s)'):\n",
    "    dname, size, nr, qlen = parse_data_info(data_info)\n",
    "    qlen_list = list(map(lambda x:int(x[0]), get_did_list(data_info)))\n",
    "    df = df_time_by_qlen(data_info, alg_list=alg_list)\n",
    "    f, axes = plt.subplots(1, 5, figsize=(25, 5), sharex=False, sharey=False)\n",
    "#     for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "#         sb.lineplot(data=df[df.theta==theta], x=\"n\", y=\"Time_Total\", hue=\"setting\", marker='o', ax=axes[0,i])\n",
    "#         axes[0,i].set(ylabel='Total Time (sec)', xscale='log', yscale='log')\n",
    "    for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "        sb.lineplot(data=df[df.theta==theta], x=\"qlen\", y=y, hue=\"setting\", marker='o', ax=axes[i])\n",
    "        axes[i].set(xticks=qlen_list, ylabel=ylabel, yscale='log', title='theta=%.1f'%theta)\n",
    "        if i == 4: axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        else: axes[i].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_by_nr(data_info, alg_list=alg_list):\n",
    "    df = df_time_by_nr(data_info, alg_list=alg_list)\n",
    "    f, axes = plt.subplots(1, 5, figsize=(25, 5), sharex=False, sharey=False)\n",
    "#     for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "#         sb.lineplot(data=df[df.theta==theta], x=\"n\", y=\"Time_Total\", hue=\"setting\", marker='o', ax=axes[0,i])\n",
    "#         axes[0,i].set(ylabel='Total Time (sec)', xscale='log', yscale='log')\n",
    "    for i, theta in zip(range(5), [0.6, 0.7, 0.8, 0.9, 1.0]):\n",
    "        sb.lineplot(data=df[df.theta==theta], x=\"nr\", y=\"Time_SearchPerQuery_MEAN\", hue=\"setting\", marker='o', ax=axes[i])\n",
    "        axes[i].set(ylabel='Mean query time (s)', xscale='log', yscale='log', title='theta=%.1f'%theta)\n",
    "        if i == 4: axes[i].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        else: axes[i].get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_alg(alg0_name, alg1_name):\n",
    "    aid0 = dict_alg[alg0_name]\n",
    "    aid1 = dict_alg[alg1_name]\n",
    "    predicates = ' '.join(['AND (algorithm_id={} OR algorithm_id={})'.format(aid0, aid1)])\n",
    "    query = query_tmpl.format(predicates)\n",
    "    output_list = []\n",
    "    for row in execute_query(query):\n",
    "        dict_param = str2dict(row['parameter'])\n",
    "        dict_rslt = str2dict(row['result'])\n",
    "        bLF, bPF = map(lambda x: x == 'true', [dict_param[key] for key in ['bLF', 'bPF']])\n",
    "        idx_impl = dict_param['index_impl']\n",
    "\n",
    "        output = {}\n",
    "        output['dataset'] = dict_rslt['Dataset_Name']\n",
    "        output['size'] = dict_rslt['Dataset_Name']\n",
    "        output['alg'] = dict_rslt['Alg_Name']+'_'+dict_rslt['Alg_Version']\n",
    "        output['theta'] = float(dict_param['theta'])\n",
    "        output['setting'] = get_setting_label(bLF, bPF, idx_impl)\n",
    "        if output['setting'] is None: continue\n",
    "        output['Time_Total'] = float(dict_rslt['Time_Total'])/1000\n",
    "        try: output['Time_QS_Total'] = float(dict_rslt['Time_QSTotal'])/1000\n",
    "        except: output['Time_QS_Total'] = float(dict_rslt['Time_QS_Total'])/1000\n",
    "        try: output['Time_TS_Total'] = float(dict_rslt['Time_TSTotal'])/1000\n",
    "        except: output['Time_TS_Total'] = float(dict_rslt['Time_TS_Total'])/1000\n",
    "        output['Time_Search'] = output['Time_QS_Total'] + output['Time_TS_Total']\n",
    "        output['Num_Verified'] = int(dict_rslt['Num_QS_Verified']) + int(dict_rslt['Num_TS_Verified'])\n",
    "        output['Num_QS_Result'] = int(dict_rslt['Num_QS_Result'])\n",
    "        output['Num_TS_Result'] = int(dict_rslt['Num_TS_Result'])\n",
    "        \n",
    "        output_list.append(output)\n",
    "    df = pd.DataFrame.from_dict(output_list)\n",
    "    df.setting = pd.Categorical(df.setting, categories=['NoFilter', 'IF', 'ICF', 'NoIndex', 'NaivePF', 'IPF', 'LF', 'PF'])\n",
    "    \n",
    "    df0 = df[df.alg==alg0_name].drop(['alg'], axis=1)\n",
    "    df1 = df[df.alg==alg1_name].drop(['alg'], axis=1)\n",
    "    df_merged = pd.merge(df0, df1, on=['dataset', 'size', 'theta', 'setting'], how='outer', suffixes=['_0','_1'])\n",
    "    df_merged['diff_Time'] = df_merged['Time_Total_0'] - df_merged['Time_Total_1']\n",
    "    df_merged['diff_Time_ratio'] = (df_merged['Time_Total_0'] - df_merged['Time_Total_1'])/df_merged['Time_Total_0']\n",
    "    df_merged['diff_Time_Search'] = df_merged['Time_Search_0'] - df_merged['Time_Search_1']\n",
    "    df_merged['diff_Time_Search_ratio'] = (df_merged['Time_Search_0'] - df_merged['Time_Search_1'])/df_merged['Time_Search_0']\n",
    "    df_merged['diff_Verify'] = df_merged['Num_Verified_0'] - df_merged['Num_Verified_1']\n",
    "    df_merged['diff_Verify_ratio'] = (df_merged['Num_Verified_0'] - df_merged['Num_Verified_1'])/df_merged['Num_Verified_0']\n",
    "    df_merged['diff_QS_Result'] = df_merged['Num_QS_Result_0'] - df_merged['Num_QS_Result_1']\n",
    "    df_merged['diff_TS_Result'] = df_merged['Num_TS_Result_0'] - df_merged['Num_TS_Result_1']\n",
    "    print('diff_Time:',df_merged['diff_Time'].mean())\n",
    "    print('diff_Time_ratio:',df_merged['diff_Time_ratio'].mean())\n",
    "    print('diff_Time_Search:',df_merged['diff_Time_Search'].mean())\n",
    "    print('diff_Time_Search_ratio:',df_merged['diff_Time_Search_ratio'].mean())\n",
    "    print('diff_Verify:',df_merged['diff_Verify'].mean())\n",
    "    print('diff_Verify_ratio:',df_merged['diff_Verify_ratio'].mean())\n",
    "    print('diff_QS_Result:',df_merged['diff_QS_Result'].mean())\n",
    "    print('diff_TS_Result:',df_merged['diff_TS_Result'].mean())\n",
    "    df_merged = df_merged.reindex(sorted(df_merged.columns), axis=1)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_comparison():\n",
    "    \n",
    "    def compare_algs(df, alg0, alg1, data_info=None, measure='Time_SearchPerQuery_MEAN'):\n",
    "        vals0 = df[df.setting==alg0][measure].values\n",
    "        vals1 = df[df.setting==alg1][measure].values\n",
    "        n = min(len(vals0), len(vals1))\n",
    "        print(measure, '' if data_info is None else data_info.name, '{}/{}'.format(alg0, alg1), vals0[:n]/vals1[:n])\n",
    "    \n",
    "    df = df_from_PrefixSearchFilterPowerTest()\n",
    "    df = df[df.theta==theta0][df.n==n0][df.qlen==qlen0]\n",
    "    compare_algs(df, 'IF', 'NaivePF', measure='Num_Verified')\n",
    "    compare_algs(df, 'IF', 'ICF', measure='Num_Verified')\n",
    "    compare_algs(df, 'IF', 'IPF', measure='Num_Verified')\n",
    "    \n",
    "    for data_info in [DataInfo('WIKI', '*', '107836', '3')]:#, DataInfo('PUBMED', '*', '79011', '3'), DataInfo('AMAZON', '*', '107836', '3')]:\n",
    "        df = df_time_by_size(data_info)\n",
    "        df = df[df.theta==theta0]\n",
    "        for setting in ['IPF', 'LF', 'PF']:\n",
    "            compare_algs(df, 'ICF', setting)\n",
    "        compare_algs(df, 'NaivePF', 'PF')\n",
    "        compare_algs(df, 'IF', 'NaivePF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_heuristic_accuracy():\n",
    "    df0 = df_from_ExactPrefixSearch()\n",
    "    df1 = df_acc()\n",
    "    df = df0.merge(df1, on=['data_name', 'n', 'nr', 'qlen', 'theta'], suffixes=['0',''], how='inner')\n",
    "    df = df[['data_name', 'n', 'nr', 'qlen', 'theta', 'setting', 'Num_Result0', 'Num_Result', 'Num_QS_Result0', 'Num_QS_Result', 'Num_TS_Result0', 'Num_TS_Result']]\n",
    "    df['Acc'] = df['Num_Result']/df['Num_Result0']\n",
    "    df['Acc_QS'] = df['Num_QS_Result']/df['Num_QS_Result0']\n",
    "    df['Acc_TS'] = df['Num_TS_Result']/df['Num_TS_Result0']\n",
    "\n",
    "    df = df[df.n==100000][df.nr==31622][df.setting=='PF']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_comparison():\n",
    "    theta0 = 0.7\n",
    "    qlen0 = 5\n",
    "    n0 = 100000\n",
    "    \n",
    "    def compare_algs(df, alg0, alg1, data_info=None, measure='Time_SearchPerQuery_MEAN'):\n",
    "        vals0 = df[df.setting==alg0][measure].values\n",
    "        vals1 = df[df.setting==alg1][measure].values\n",
    "        n = min(len(vals0), len(vals1))\n",
    "        print(measure, '' if data_info is None else data_info.name, '{}/{}'.format(alg0, alg1), vals0[:n]/vals1[:n])\n",
    "    \n",
    "    df = df_from_PrefixSearchFilterPowerTest()\n",
    "    df = df[df.theta==theta0][df.n==n0][df.qlen==qlen0]\n",
    "    compare_algs(df, 'LSS-NAIVE', 'LSS-COUNT', measure='Num_Verified')\n",
    "    compare_algs(df, 'LSS-COUNT', 'LSS-POS', measure='Num_Verified')\n",
    "    compare_algs(df, 'LSS-POS', 'LSS-LEN', measure='Num_Verified')\n",
    "    compare_algs(df, 'LSS-LEN', 'LSS-PREFIX', measure='Num_Verified')\n",
    "    compare_algs(df, 'LSS-NAIVE', 'LSS-PKDUCK', measure='Num_Verified')\n",
    "    \n",
    "    print('Varying nt')\n",
    "    for data_info in [DataInfo('WIKI', '*', '107836', '5'), DataInfo('PUBMED', '*', '79011', '5'), DataInfo('AMAZON', '*', '107836', '5')]:\n",
    "        df = df_time_by_size(data_info)\n",
    "        df = df[df.theta==theta0]\n",
    "#         for setting in ['LSS-POS', 'LSS-LEN', 'LSS-PREFIX']:\n",
    "#             compare_algs(df, 'LSS-COUNT', setting, data_info)\n",
    "#         compare_algs(df, 'LSS-NAIVE', 'LSS-PREFIX', data_info)\n",
    "        compare_algs(df, 'LSS-P+L', 'LSS-C+P', data_info)\n",
    "        compare_algs(df, 'LSS-P+L', 'LSS-C+P+L', data_info)\n",
    "        \n",
    "    print('Varying qlen')\n",
    "    for data_info in [DataInfo('WIKI', '100000', '107836', '*'), DataInfo('PUBMED', '100000', '79011', '*'), DataInfo('AMAZON', '100000', '107836', '*')]:\n",
    "        df = df_time_by_qlen(data_info)\n",
    "        df = df[df.theta==theta0]\n",
    "        for setting in ['LSS-POS', 'LSS-LEN', 'LSS-PREFIX']:\n",
    "            compare_algs(df, 'LSS-COUNT', setting, data_info)\n",
    "        compare_algs(df, 'LSS-NAIVE', 'LSS-PREFIX', data_info)\n",
    "        compare_algs(df, 'LSS-INDEX', 'LSS-NAIVE', data_info)\n",
    "\n",
    "    print('Varying nr')\n",
    "    for data_info in [DataInfo('WIKI', '100000', '*', '5'), DataInfo('PUBMED', '100000', '*', '5'), DataInfo('AMAZON', '100000', '*', '5')]:\n",
    "        df = df_time_by_nr(data_info)\n",
    "        df = df[df.theta==theta0]\n",
    "#         for setting in ['LSS-POS', 'LSS-LEN', 'LSS-PREFIX']:\n",
    "#             compare_algs(df, 'LSS-COUNT', setting, data_info)\n",
    "#         compare_algs(df, 'LSS-NAIVE', 'LSS-PREFIX', data_info)\n",
    "        compare_algs(df, 'LSS-P', 'LSS-C+P', data_info)\n",
    "        compare_algs(df, 'LSS-P', 'LSS-C+P+L', data_info)\n",
    "        compare_algs(df, 'LSS-P+L', 'LSS-C+P', data_info)\n",
    "        compare_algs(df, 'LSS-P+L', 'LSS-C+P+L', data_info)\n",
    "\n",
    "        \n",
    "    print('Varying theta')\n",
    "    for data_info in [DataInfo('WIKI', '100000', '107836', '5'), DataInfo('PUBMED', '100000', '79011', '5'), DataInfo('AMAZON', '100000', '107836', '5')]:\n",
    "        df = df_time_by_filtering(data_info).groupby(['theta', 'setting']).head(1).sort_values('theta')\n",
    "        compare_algs(df, 'LSS-P+L', 'LSS-C+P', data_info)\n",
    "        compare_algs(df, 'LSS-P+L', 'LSS-C+P+L', data_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
